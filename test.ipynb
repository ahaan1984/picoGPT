{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt import SingleHeadAttention, MultiHeadAttention, FeedForward, Block, GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "batch_size = 16 # how many independent sequences will we process in parallel?\n",
    "block_size = 32 # what is the maximum context length for predictions?\n",
    "max_iters = 5000\n",
    "eval_interval = 100\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 64\n",
    "n_head = 4\n",
    "n_layer = 4\n",
    "dropout = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1a97f474bd0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(2525)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tiny-shakespeare.txt', 'r', encoding='utf-8') as f:\n",
    "    text=f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115394"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "print(''.join(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(chars)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = {s:i for i, s in enumerate(chars)}\n",
    "itos = {i:s for s, i in stoi.items()}\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: ''.join([itos[i] for i in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31, 61, 53, 56, 42, 1, 47, 52, 1, 25, 53, 59, 58, 46, 6, 1, 18, 47, 56, 43, 1, 17, 63, 43, 57]\n",
      "Hello, World!\n"
     ]
    }
   ],
   "source": [
    "print(encode(\"Sword in Mouth, Fire Eyes\"))\n",
    "print(decode(encode(\"Hello, World!\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
      "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
      "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
      "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
      "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
      "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
      "        53, 59])\n"
     ]
    }
   ],
   "source": [
    "print(data[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i: i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1: i+block_size+1] for i in ix])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb, yb = get_batch('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 32]),\n",
       " tensor([[56, 42, 57, 46, 47, 54,  1, 54, 50, 43, 39, 57, 43,  1, 58, 53,  1, 39,\n",
       "          57, 49,  8,  0,  0, 20, 13, 31, 32, 21, 26, 19, 31, 10],\n",
       "         [ 1, 51, 63,  1, 51, 47, 57, 44, 53, 56, 58, 59, 52, 43,  5, 57,  1, 41,\n",
       "          56, 53, 57, 57, 11,  0, 13, 63,  6,  1, 39, 63,  6,  1],\n",
       "         [59, 43,  8,  0, 21,  1, 61, 53, 59, 50, 42,  1, 52, 53, 58,  7,  7, 58,\n",
       "          46, 53, 59, 45, 46,  1,  5, 58, 47, 57,  1, 51, 63,  1],\n",
       "         [ 1, 51, 43,  1, 42, 53,  1, 40, 39, 41, 49,  1, 56, 43, 41, 43, 47, 60,\n",
       "          43,  1, 58, 46, 43,  1, 44, 50, 53, 59, 56,  1, 53, 44],\n",
       "         [ 1, 58, 56, 59, 43, 12,  0,  0, 17, 24, 14, 27, 35, 10,  0, 27,  1, 58,\n",
       "          46, 53, 59,  1, 41, 39, 47, 58, 47, 44, 44,  2,  1, 27],\n",
       "         [ 1, 58, 46, 39, 58,  1, 58, 56, 59, 57, 58,  1, 58, 53,  1, 58, 46, 43,\n",
       "          43,  8,  0,  0, 15, 13, 25, 21, 24, 24, 27, 10,  0, 20],\n",
       "         [53, 49,  1, 58, 53,  1, 55, 59, 43, 52, 41, 46,  1, 47, 58,  6,  0, 31,\n",
       "          46, 43,  1, 61, 53, 59, 50, 42,  1, 58, 53,  1, 43, 39],\n",
       "         [43, 52, 58,  1, 44, 53, 56,  1, 51, 43, 11,  0, 26, 53,  6,  1, 47, 44,\n",
       "           1, 21,  1, 42, 47, 45, 45,  5, 42,  1, 59, 54,  1, 58],\n",
       "         [57,  1, 57, 58, 39, 58, 59, 58, 43, 57,  1, 41, 39, 52, 41, 43, 50, 50,\n",
       "           5, 42,  1, 39, 52, 42,  1, 46, 47, 57,  1, 58, 56, 43],\n",
       "         [50, 63,  1, 45, 47, 44, 58, 12,  0,  0, 19, 24, 27, 33, 15, 17, 31, 32,\n",
       "          17, 30, 10,  0, 13, 63,  6,  1, 40, 63,  1, 51, 63,  1],\n",
       "         [43, 56,  6,  1, 40, 63,  1, 58, 46, 43,  1, 51, 39, 52,  1, 58, 46, 39,\n",
       "          58,  1, 57, 50, 43, 61,  1, 46, 43, 56,  1, 40, 56, 53],\n",
       "         [52, 43, 62, 58,  1, 42, 43, 45, 56, 43, 43,  1, 47, 52,  1, 46, 53, 54,\n",
       "          43,  8,  0,  0, 19, 30, 17, 17, 26, 10,  0, 35, 43, 50],\n",
       "         [39, 58,  1, 61, 39, 63,  1, 58, 46, 53, 59,  1, 61, 43, 56, 58,  8,  0,\n",
       "           0, 24, 17, 27, 26, 32, 17, 31, 10,  0, 19, 53,  1, 53],\n",
       "         [58, 46, 43, 56,  6,  1, 54, 56, 43, 57, 43, 52, 58, 50, 63,  8,  0, 14,\n",
       "          59, 58,  1, 14, 39, 56, 52, 39, 56, 42, 47, 52, 43,  1],\n",
       "         [40, 39, 57, 47, 50, 47, 57, 49, 57,  6,  1, 58, 53,  1, 57, 58, 56, 47,\n",
       "          49, 43,  1, 58, 46, 43, 43,  1, 42, 43, 39, 42,  2,  0],\n",
       "         [24, 24, 27, 10,  0, 20, 53, 61,  1, 52, 53, 61,  6,  1, 45, 53, 53, 42,\n",
       "           1, 44, 43, 50, 50, 53, 61,  2,  1, 61, 46, 63,  1, 57]]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"inputs:\")\n",
    "xb.shape, xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 32]),\n",
       " tensor([[42, 57, 46, 47, 54,  1, 54, 50, 43, 39, 57, 43,  1, 58, 53,  1, 39, 57,\n",
       "          49,  8,  0,  0, 20, 13, 31, 32, 21, 26, 19, 31, 10,  0],\n",
       "         [51, 63,  1, 51, 47, 57, 44, 53, 56, 58, 59, 52, 43,  5, 57,  1, 41, 56,\n",
       "          53, 57, 57, 11,  0, 13, 63,  6,  1, 39, 63,  6,  1, 44],\n",
       "         [43,  8,  0, 21,  1, 61, 53, 59, 50, 42,  1, 52, 53, 58,  7,  7, 58, 46,\n",
       "          53, 59, 45, 46,  1,  5, 58, 47, 57,  1, 51, 63,  1, 44],\n",
       "         [51, 43,  1, 42, 53,  1, 40, 39, 41, 49,  1, 56, 43, 41, 43, 47, 60, 43,\n",
       "           1, 58, 46, 43,  1, 44, 50, 53, 59, 56,  1, 53, 44,  1],\n",
       "         [58, 56, 59, 43, 12,  0,  0, 17, 24, 14, 27, 35, 10,  0, 27,  1, 58, 46,\n",
       "          53, 59,  1, 41, 39, 47, 58, 47, 44, 44,  2,  1, 27,  1],\n",
       "         [58, 46, 39, 58,  1, 58, 56, 59, 57, 58,  1, 58, 53,  1, 58, 46, 43, 43,\n",
       "           8,  0,  0, 15, 13, 25, 21, 24, 24, 27, 10,  0, 20, 39],\n",
       "         [49,  1, 58, 53,  1, 55, 59, 43, 52, 41, 46,  1, 47, 58,  6,  0, 31, 46,\n",
       "          43,  1, 61, 53, 59, 50, 42,  1, 58, 53,  1, 43, 39, 41],\n",
       "         [52, 58,  1, 44, 53, 56,  1, 51, 43, 11,  0, 26, 53,  6,  1, 47, 44,  1,\n",
       "          21,  1, 42, 47, 45, 45,  5, 42,  1, 59, 54,  1, 58, 46],\n",
       "         [ 1, 57, 58, 39, 58, 59, 58, 43, 57,  1, 41, 39, 52, 41, 43, 50, 50,  5,\n",
       "          42,  1, 39, 52, 42,  1, 46, 47, 57,  1, 58, 56, 43, 39],\n",
       "         [63,  1, 45, 47, 44, 58, 12,  0,  0, 19, 24, 27, 33, 15, 17, 31, 32, 17,\n",
       "          30, 10,  0, 13, 63,  6,  1, 40, 63,  1, 51, 63,  1, 44],\n",
       "         [56,  6,  1, 40, 63,  1, 58, 46, 43,  1, 51, 39, 52,  1, 58, 46, 39, 58,\n",
       "           1, 57, 50, 43, 61,  1, 46, 43, 56,  1, 40, 56, 53, 58],\n",
       "         [43, 62, 58,  1, 42, 43, 45, 56, 43, 43,  1, 47, 52,  1, 46, 53, 54, 43,\n",
       "           8,  0,  0, 19, 30, 17, 17, 26, 10,  0, 35, 43, 50, 50],\n",
       "         [58,  1, 61, 39, 63,  1, 58, 46, 53, 59,  1, 61, 43, 56, 58,  8,  0,  0,\n",
       "          24, 17, 27, 26, 32, 17, 31, 10,  0, 19, 53,  1, 53, 52],\n",
       "         [46, 43, 56,  6,  1, 54, 56, 43, 57, 43, 52, 58, 50, 63,  8,  0, 14, 59,\n",
       "          58,  1, 14, 39, 56, 52, 39, 56, 42, 47, 52, 43,  1, 51],\n",
       "         [39, 57, 47, 50, 47, 57, 49, 57,  6,  1, 58, 53,  1, 57, 58, 56, 47, 49,\n",
       "          43,  1, 58, 46, 43, 43,  1, 42, 43, 39, 42,  2,  0,  0],\n",
       "         [24, 27, 10,  0, 20, 53, 61,  1, 52, 53, 61,  6,  1, 45, 53, 53, 42,  1,\n",
       "          44, 43, 50, 50, 53, 61,  2,  1, 61, 46, 63,  1, 57, 46]]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"targets:\")\n",
    "yb.shape, yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT(vocab_size)\n",
    "m = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209729 M parameters\n"
     ]
    }
   ],
   "source": [
    "print(sum(p.numel() for p in m.parameters()), 'M parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 4.1828, val loss 4.1848\n",
      "step 100: train loss 2.6221, val loss 2.6213\n",
      "step 200: train loss 2.4990, val loss 2.5027\n",
      "step 300: train loss 2.4111, val loss 2.4222\n",
      "step 400: train loss 2.3230, val loss 2.3510\n",
      "step 500: train loss 2.2918, val loss 2.3061\n",
      "step 600: train loss 2.2451, val loss 2.2790\n",
      "step 700: train loss 2.1976, val loss 2.2244\n",
      "step 800: train loss 2.1602, val loss 2.2013\n",
      "step 900: train loss 2.1441, val loss 2.1673\n",
      "step 1000: train loss 2.1045, val loss 2.1384\n",
      "step 1100: train loss 2.0673, val loss 2.1102\n",
      "step 1200: train loss 2.0493, val loss 2.1136\n",
      "step 1300: train loss 2.0296, val loss 2.0734\n",
      "step 1400: train loss 2.0225, val loss 2.0802\n",
      "step 1500: train loss 1.9889, val loss 2.0705\n",
      "step 1600: train loss 1.9933, val loss 2.0573\n",
      "step 1700: train loss 1.9578, val loss 2.0298\n",
      "step 1800: train loss 1.9512, val loss 2.0265\n",
      "step 1900: train loss 1.9282, val loss 2.0053\n",
      "step 2000: train loss 1.9133, val loss 2.0137\n",
      "step 2100: train loss 1.9098, val loss 2.0113\n",
      "step 2200: train loss 1.8991, val loss 1.9914\n",
      "step 2300: train loss 1.8929, val loss 2.0006\n",
      "step 2400: train loss 1.8752, val loss 1.9827\n",
      "step 2500: train loss 1.8743, val loss 1.9725\n",
      "step 2600: train loss 1.8469, val loss 1.9627\n",
      "step 2700: train loss 1.8457, val loss 1.9540\n",
      "step 2800: train loss 1.8435, val loss 1.9759\n",
      "step 2900: train loss 1.8307, val loss 1.9631\n",
      "step 3000: train loss 1.8164, val loss 1.9467\n",
      "step 3100: train loss 1.8203, val loss 1.9268\n",
      "step 3200: train loss 1.8060, val loss 1.9331\n",
      "step 3300: train loss 1.8056, val loss 1.9267\n",
      "step 3400: train loss 1.7944, val loss 1.9178\n",
      "step 3500: train loss 1.7930, val loss 1.9243\n",
      "step 3600: train loss 1.7768, val loss 1.9260\n",
      "step 3700: train loss 1.7818, val loss 1.9257\n",
      "step 3800: train loss 1.7665, val loss 1.9102\n",
      "step 3900: train loss 1.7735, val loss 1.8966\n",
      "step 4000: train loss 1.7471, val loss 1.8968\n",
      "step 4100: train loss 1.7600, val loss 1.8935\n",
      "step 4200: train loss 1.7529, val loss 1.9027\n",
      "step 4300: train loss 1.7515, val loss 1.8838\n",
      "step 4400: train loss 1.7407, val loss 1.8953\n",
      "step 4500: train loss 1.7219, val loss 1.8727\n",
      "step 4600: train loss 1.7235, val loss 1.8624\n",
      "step 4700: train loss 1.7237, val loss 1.8903\n",
      "step 4800: train loss 1.7150, val loss 1.8627\n",
      "step 4900: train loss 1.7231, val loss 1.8800\n",
      "step 4999: train loss 1.7243, val loss 1.8753\n"
     ]
    }
   ],
   "source": [
    "for iter in range(max_iters):\n",
    "\n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimiser.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimiser.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wargele timen-sheed the hear lose a as\n",
      "quady bajuptaul indent ply, take of Royalt.\n",
      "And they to we deps to foo will hepor-dreeagurius hill now your,\n",
      "Whould can exe made a caffor boor,\n",
      "Basonded, fienk;\n",
      "Why my helneforth a beely the in the ploves to prom upon her my well plesicur a.\n",
      "\n",
      "And live, mers?\n",
      "O, like hon,\n",
      "Bamine father ble bees- Lord be me moned very took ou ref op highame and gaingent!\n",
      "\n",
      "LEONTA:\n",
      "His this to stisfaw!\n",
      "\n",
      "CLARENE:\n",
      "My toe?\n",
      "\n",
      "BUCKIXE:\n",
      "This yout kmarl, my abod loduck and a recial'd;\n",
      "Light\n",
      "Hath yesures faid, I parcutera abond\n",
      "the ithe say once that is and Jull's kep, sou\n",
      "We satioud; a kneed the have a juctity:\n",
      "As sead ours, here,\n",
      "The water fack ith think,\n",
      "Whult ware 'ting of your oiss.\n",
      "\n",
      "CALUS:\n",
      "Cissshaface; to help in that a day have prrectue ity fivence,\n",
      "The on offeshy motsiain worn you\n",
      "deed and theeptare!\n",
      "\n",
      "ISABELLA:\n",
      "Pospeade so end, conture triess;\n",
      "Let the do peacuse of with\n",
      "And good begent; whep daying anble: in I trayegthe ban a mpeak eshices\n",
      "Mith manion offen the hOur us, 'tistears pead\n",
      "To thou\n",
      "hondedly didde thase swast shrous, knows held me ispin clent; am he as wre'd.\n",
      "\n",
      "CINIUS:\n",
      "The fathe one for in that mann. he so,\n",
      "You rempate un his poove,--oldign.\n",
      "\n",
      "BOfige, bes mixee.\n",
      "I have mise towes\n",
      "They;\n",
      "They thead took Goo thit the toe helve\n",
      "he morel\n",
      "faw die wayy to for you Have wither hear.\n",
      "The, notios, you hem; and you you as;\n",
      "Mark and I ant a himse thy folther bad shallife at band eye you,\n",
      "Lep near a I'll diy, anties son, best you.\n",
      "\n",
      "KING WARDway me, teling; I' thee.\n",
      "\n",
      "Frayse: so earlns your floriciom lies you.\n",
      "\n",
      "BQUENE:\n",
      "Aye that they Edonce, sin deant he you if thy have,\n",
      "Thou, bate I hast sir; think thou had ithes me, in Lood,\n",
      "Angomet his thy that them; nou, whan is.\n",
      "\n",
      "Citio, ' is me, if thow would, of his hargy\n",
      "I bok life\n",
      "a as a the reping fathols intowerors,\n",
      "ly my have your haught.\n",
      "The have of take shne denet bance ass of LAught we nist I compleon, is unch and yet,\n",
      "The face now ithe.\n",
      "\n",
      "BUCKINGA:\n",
      "Upormhovow, pase.\n",
      "\n",
      "\n",
      "RAKING HENRY VI:\n",
      "Then ciust true fewnt unju\n"
     ]
    }
   ],
   "source": [
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "print(decode(m.generate(context, max_new_tokens=2000)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
