{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt import SingleHeadAttention, MultiHeadAttention, FeedForward, Block, GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "batch_size = 32\n",
    "block_size = 64\n",
    "max_iters = 5000\n",
    "eval_interval = 100\n",
    "learning_rate = 3e-4\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 204\n",
    "n_head = 6\n",
    "n_layer = 4\n",
    "dropout= 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1cf71e78bd0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(2525)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tiny-shakespeare.txt', 'r', encoding='utf-8') as f:\n",
    "    text=f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115394"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "print(''.join(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(chars)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = {s:i for i, s in enumerate(chars)}\n",
    "itos = {i:s for s, i in stoi.items()}\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: ''.join([itos[i] for i in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31, 61, 53, 56, 42, 1, 47, 52, 1, 25, 53, 59, 58, 46, 6, 1, 18, 47, 56, 43, 1, 17, 63, 43, 57]\n",
      "Hello, World!\n"
     ]
    }
   ],
   "source": [
    "print(encode(\"Sword in Mouth, Fire Eyes\"))\n",
    "print(decode(encode(\"Hello, World!\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
      "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
      "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
      "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
      "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
      "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
      "        53, 59])\n"
     ]
    }
   ],
   "source": [
    "print(data[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i: i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1: i+block_size+1] for i in ix])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb, yb = get_batch('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]),\n",
       " tensor([[46, 43,  1,  ..., 58,  1, 39],\n",
       "         [57, 58, 43,  ...,  1, 46, 53],\n",
       "         [47, 56, 50,  ..., 43,  1, 50],\n",
       "         ...,\n",
       "         [43, 52,  1,  ..., 58, 46, 43],\n",
       "         [45, 56, 39,  ...,  1, 50, 53],\n",
       "         [50, 41, 46,  ...,  1, 39, 45]]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"inputs:\")\n",
    "xb.shape, xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]),\n",
       " tensor([[43,  1, 46,  ...,  1, 39,  1],\n",
       "         [58, 43, 56,  ..., 46, 53, 61],\n",
       "         [56, 50, 63,  ...,  1, 50, 53],\n",
       "         ...,\n",
       "         [52,  1, 58,  ..., 46, 43, 47],\n",
       "         [56, 39, 52,  ..., 50, 53, 60],\n",
       "         [41, 46,  1,  ..., 39, 45, 53]]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"targets:\")\n",
    "yb.shape, yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT(vocab_size)\n",
    "m = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2045777 M parameters\n"
     ]
    }
   ],
   "source": [
    "print(sum(p.numel() for p in m.parameters()), 'M parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 4.2093, val loss 4.2130\n",
      "step 100: train loss 2.4895, val loss 2.4948\n",
      "step 200: train loss 2.3561, val loss 2.3703\n",
      "step 300: train loss 2.2680, val loss 2.2864\n",
      "step 400: train loss 2.1559, val loss 2.1854\n",
      "step 500: train loss 2.0416, val loss 2.0983\n",
      "step 600: train loss 1.9517, val loss 2.0308\n",
      "step 700: train loss 1.8919, val loss 1.9898\n",
      "step 800: train loss 1.8265, val loss 1.9304\n",
      "step 900: train loss 1.7719, val loss 1.9013\n",
      "step 1000: train loss 1.7304, val loss 1.8792\n",
      "step 1100: train loss 1.6948, val loss 1.8563\n",
      "step 1200: train loss 1.6562, val loss 1.8164\n",
      "step 1300: train loss 1.6318, val loss 1.8062\n",
      "step 1400: train loss 1.6024, val loss 1.7845\n",
      "step 1500: train loss 1.5820, val loss 1.7430\n",
      "step 1600: train loss 1.5563, val loss 1.7435\n",
      "step 1700: train loss 1.5470, val loss 1.7361\n",
      "step 1800: train loss 1.5268, val loss 1.7129\n",
      "step 1900: train loss 1.5155, val loss 1.7029\n",
      "step 2000: train loss 1.4938, val loss 1.6972\n",
      "step 2100: train loss 1.4822, val loss 1.6781\n",
      "step 2200: train loss 1.4738, val loss 1.6634\n",
      "step 2300: train loss 1.4701, val loss 1.6529\n",
      "step 2400: train loss 1.4561, val loss 1.6507\n",
      "step 2500: train loss 1.4463, val loss 1.6456\n",
      "step 2600: train loss 1.4407, val loss 1.6421\n",
      "step 2700: train loss 1.4303, val loss 1.6430\n",
      "step 2800: train loss 1.4195, val loss 1.6312\n",
      "step 2900: train loss 1.4116, val loss 1.6252\n",
      "step 3000: train loss 1.4094, val loss 1.6197\n",
      "step 3100: train loss 1.4035, val loss 1.6178\n",
      "step 3200: train loss 1.3866, val loss 1.6072\n",
      "step 3300: train loss 1.3826, val loss 1.6064\n",
      "step 3400: train loss 1.3763, val loss 1.5991\n",
      "step 3500: train loss 1.3738, val loss 1.5918\n",
      "step 3600: train loss 1.3669, val loss 1.5852\n",
      "step 3700: train loss 1.3735, val loss 1.6052\n",
      "step 3800: train loss 1.3655, val loss 1.5875\n",
      "step 3900: train loss 1.3503, val loss 1.5883\n",
      "step 4000: train loss 1.3471, val loss 1.5801\n",
      "step 4100: train loss 1.3438, val loss 1.5807\n",
      "step 4200: train loss 1.3411, val loss 1.5832\n",
      "step 4300: train loss 1.3379, val loss 1.5778\n",
      "step 4400: train loss 1.3336, val loss 1.5805\n",
      "step 4500: train loss 1.3262, val loss 1.5766\n",
      "step 4600: train loss 1.3200, val loss 1.5811\n",
      "step 4700: train loss 1.3196, val loss 1.5779\n",
      "step 4800: train loss 1.3141, val loss 1.5823\n",
      "step 4900: train loss 1.3115, val loss 1.5793\n",
      "step 4999: train loss 1.3048, val loss 1.5626\n"
     ]
    }
   ],
   "source": [
    "for iter in range(max_iters):\n",
    "\n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimiser.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimiser.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "And much add leave a cure\n",
      "Here had with his rage besolved ve me they me, rests!\n",
      "I do mean you opine of faith,--o yond with good with\n",
      "you, a crave. O Vilta, out--the maid, cross I have been,\n",
      "But so I wonder fray thee to the king.\n",
      "\n",
      "But Mowbray made to Bolingbroke:\n",
      "Out, the boy look but only the benefit.\n",
      "\n",
      "MOPSA:\n",
      "Say you, methinks, Clarence, father, thy same to their\n",
      "that with childish an execute, I love the most.\n",
      "Now, mine way\n",
      "Made 'Twixt 'tweres, we have no cool! When you are\n",
      "care many man of the maid's wrath: alive again,\n",
      "I must be record for your grumented son.\n",
      "Ah, a noble sit, Jures. Greum! Ah, blood Marcius.\n",
      "\n",
      "JULIET:\n",
      "Wail the had trobb'd, and only of door.\n",
      "\n",
      "Second Murderer:\n",
      "It eremember, the hate the treason, thou lay'st quickly'st.\n",
      "I'll strength thee and a-trueverence.\n",
      "'Thou art the carest on a change at is try'vouch.\n",
      "Fivinctiry, 'tis not me only, and spreak\n",
      "Met some from whither firice and me\n",
      "Make traitor betting from, fiend swaiting to\n",
      "Fair one damnous more, senate, for what great they?\n",
      "His instly gracious cousin to we 't. Harry speak\n",
      "Made your wind heir blessing.\n",
      "\n",
      "ANGELO:\n",
      "I call 't God's give.\n",
      "\n",
      "QUEEN ELIZABETH:\n",
      "I fail to off, dare my fortrument i to on you\n",
      "I circupt feebly to Angelo?\n",
      "\n",
      "RICHARD:\n",
      "They call, so; hall not having to grief.\n",
      "God-dam'st me! Pretty me, how never of myself,\n",
      "Such again, call not the being one hour and dreaks!\n",
      "You'll have a little to the worn stumage I have.\n",
      "\n",
      "EXTONH:\n",
      "I pray you all all, if I do despect.\n",
      "Thore, dear to see him he see; the death\n",
      "kill the prepared were, my father, you are dead,'\n",
      "Foit, so mean towards your hearts; as I think you\n",
      "Mouth tie stabboward of Warwick at Resta be are\n",
      "walk thy broil to the danger of our childishonour\n",
      "And radize me at none wait them\n",
      "Be; awhile, crave I see thee deter, and mawn,\n",
      "So all; that she, Cleomioner, kilp, the prince, to\n",
      "fond lastisa month thee, torment it.\n",
      "\n",
      "Nurse:\n",
      "Within till me and gross and will;\n",
      "Nurselvel, but not, supster the world,\n",
      "And make here a condemnment, 'being from Paris\n",
      "A struet dev\n"
     ]
    }
   ],
   "source": [
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "print(decode(m.generate(context, max_new_tokens=2000)[0].tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
